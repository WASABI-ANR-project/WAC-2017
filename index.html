<!DOCTYPE html>
<html>
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Telemeta 2.0</title>
    <meta name="description" content="Some description about the slides">
    <meta name="author" content="You">
    <link rel="stylesheet" href="css/main.css">
  </head>
  <body>
    <textarea id="source">class: center, middle, vertigo

# WASABI

##a two million song database project with audio and cultural metadata <br> plus WebAudio enhanced client applications

<hr>

Michel Buffa - INRIA / Wimmics<br>
Guillaume Pellerin - IRCAM<br>

### WAC 2017 - 22/08/2017 - QMUL
<img src="img/jim_horiz_blanc_1.png" height="100px" />

---
class: vertigo

#WASABI project

##Web Audio and SemAntic in the Browser for Indexation

- 42 months from 2016 Q4 to april 2020 Q2
- 750 k€ project granted by the french Research National Agency

## Partners

- INRIA (I3S)
- IRCAM (MIR + Musicology + Library)
- Deezer R&D
- Radio France Library
- Parisson

---
class: vertigo

#WASABI project

##Objectives

- Propose some new methodologies to index music in the web and audio context
- Link semantics (linked metadata) + acoustics (MIR data) + machine learning
- Develop and publish some open source web services through original APIs

##Use cases

- augmented web music browsing
- data journalism
- music composing through big data
- plagiarism or influence detection

---
class: vertigo, tight

#TimeSide

##open audio processing framework for the web

https://github.com/Parisson/TimeSide

##Use cases

- Scaled audio processing (filtering, transcoding, machine learning, etc...)
- Audio process prototyping
- Audio dynamic visualization
- Automatic segmentation and labelling synchronized with audio events
- Collaborative annotation
- Audio web services

##Features and examples

DEMO this afternoon...

---
class: vertigo
#TimeSide

.pull-left-30[
##Architecture
- streaming oriented core engine
- data persistence
]

.pull-right-70[
.right[![image-wh-bg](img/TimeSide_pipe.svg)]
]

---
class: vertigo

.pull-left-30[
#TimeSide

##Architecture
- streaming oriented core engine
- processing API and namespace
]

.pull-right-70[
```python
class DummyAnalyzer(Analyzer):
    """A dummy analyzer returning random samples from audio frames"""
    implements(IAnalyzer)

    @interfacedoc
    def setup(self, channels=None, samplerate=None, blocksize=None, totalframes=None):
        super(DummyAnalyzer, self).setup(channels, samplerate, blocksize, totalframes)
        self.values = numpy.array([0])

    @staticmethod
    @interfacedoc
    def id():
        return "dummy"

    @staticmethod
    @interfacedoc
    def name():
        return "Dummy analyzer"

    @staticmethod
    @interfacedoc
    def unit():
        return "None"

    def process(self, frames, eod=False):
        size = frames.size
        if size:
            index = numpy.random.randint(0, size, 1)
            self.values = numpy.append(self.values, frames[index])
        return frames, eod

    def post_process(self):
        result = self.new_result(data_mode='value', time_mode='global')
        result.data_object.value = self.values
        self.add_result(result)

```
]

---
class: vertigo
#TimeSide

.pull-left-30[
##Architecture
- streaming oriented core engine
- processing API and namespace
- docker packaged
- fully scalable
]

.pull-right-70[
```bash
$ git clone --recursive https://github.com/Parisson/TimeSide.git
$ docker-compose up
$ docker-compose scale worker 1024
```

```python
$ docker-compose run app python manage.py shell
>>> from timeside.models import Task
>>> tasks = Task.objects.all()
>>> for task in tasks:
>>>     task.run()
```
]

---
class: vertigo
#TimeSide

##Plugins

https://github.com/Parisson/TimeSide

https://github.com/DIADEMS/timeside-diadems

.pull-left[
- FileDecoder
- ArrayDecoder
- LiveDecoder
- VorbisEncoder
- WavEncoder
- Mp3Encoder
- FlacEncoder
- OpusEncoder
- Mp4Encoder
- AacEncoder
]

.pull-right[
- Aubio (Temporal, Pitch, etc)
- Yaafe (graph oriented)
- **VampPyHost**
- **Essentia bridge**
- **Speech detection**
- **Music detection**
- **Singing voice detection**
- **Monophony / Polyphony**
- **Dissonance**
- etc... (experimental)
]

---
class: vertigo
#TimeSide

.pull-left-30[
##Resful API

http://timeside-dev.telemeta.org/timeside/api/

- based on Django Rest Framework (extensible)
- streaming oriented (audio and data)
- user presets
]

.pull-right-70[
.right[![image-wh-bg](img/TS2_API.png)]
]

---
class: vertigo
#TimeSide

.pull-left-30[
##Player (v1, SoundManager2)

- on demand processing
- simple marker annotation
- bitmap image cache only
]

.pull-right-70[
.right[![image](img/SOLO_DUOdetection.png)]
]

---
class: vertigo

.pull-left[
#TimeSide

##Player v2 (Web Audio, prototype)

###Assumption : NO audio duration limit

###Constraint : user data persistence

- zooming
- packet streaming (audio & data)
- multiple user annotations and analysis tracks
- dynamic data rendering
]

.pull-right[
.right[![image](img/ui-telemeta-grand-2_1.png)]
]

---
class: vertigo
#TimeSide integration

.pull-left[
<img src="img/telemeta_logo_wh.png" height="100px" />

###Collaborative multimedia asset management system

https://github.com/Parisson/Telemeta

###MIR + Musicology + Archiving = MIRchiving !

###>>> active learning
]

.pull-right[
.right[![image](img/telemeta_screenshot_en_2.png)]
]

---
class: vertigo
#WASABI

##Innovative user experience / use cases

###Targets: composers, musicologists, data journalists, music schools, music engineer schools, streaming services.

###Application expected results (using WebAudio extensively)

- A full web app to browse multidimensional data (I3S)
- Collaborative Web tools for automatic, semi-automatic and manual audio indexing (Parisson, IRCAM)
- Mixing table / multitrack player, chainable high-level audio effects, guitar amp simulators, interactive audio music browser (I3S)
- Search engine driven by audio (midi input, audio extracts) (IRCAM, I3S)
- improving production metadata access and recommandation (Deezer, Radio France)
- Interactive tutorials (music and sound engineer schools)

---
class: vertigo
# WASABI

##Multitrack player (and FX) already used in music schools!
<br>

.center[
<iframe width="560" height="315" src="https://www.youtube.com/embed/DUM99xQt5fg" frameborder="0" allowfullscreen></iframe>
]

---
class: vertigo

# Conclusion

##WASABI will bring acoustics and semantics together

###2 million song dataset, mixing cultural and audio data, constantly being enriched

- Ongoing project, at its beginning.
- First of its kind to include both cultural + MIR + lyrics NLP analysis
- Search engine + GUI already online, will be enhanced and add many facets and WebAudio client apps
- Open source bricks
- REST API, SPARQL endpoint
- Knowledge database usable for reasoning on datas
- TRY IT! https://wasabi.i3s.unice.fr

---
class: center, middle, vertigo

# Thanks !
<hr>

##Michel Buffa, I3S / Université Côte d’Azur, France,

###buffa@i3s.unice.fr / @micbuffa

##Guillaume Pellerin, IRCAM, France

###guillaume.pellerin@ircam.fr / @yomguy

    </textarea>
    <script src="https://gnab.github.io/remark/downloads/remark-latest.min.js"></script>
    <script>window.remark || document.write(
  '<script src="js/vendor/remark.min.js"><\/script>'
)

    </script>
    <script src="js/vendor/remark-language.js"></script>
    <script src="js/main.js"></script>
  </body>
</html>